    From real business cycle and new Keynesian to DSGE Macroeconomics: facts and
                         models in the emergence of a consensus

                                              Pedro Garcia Duarte1


                                               RESUMO:
O surgimento da macroeconomia DSGE é tido ter por base uma síntese entre dois ramos da literatura
que eram vistos como antagonistas: a macroeconomia dos ciclos reais de negócios (RBC) e a novo-
keynesiana. Neste processo de síntese no qual cada grupo incorporou elementos do grupo rival, o fato
de que fatos não desaparecem, para usar as palavras de Blanchard (2009), é geralmente usado como
explicação. Entretanto, fatos empíricos em macroeconomia desempenham um papel muito longe do
ideal falsificacionista que pode caracterizar o desenvolvimento de outras ciências, porque estes fatos
são construídos com o auxílio dos modelos que eles são usados para avaliar. Portanto, a negociação
envolvida no processo de síntese passa por discussões sobre o grau de autonomia dos fatos em relação
aos modelos. Assim, a história de que foram os fatos que forçaram a convergência entre os dois grupos
antagônicos é mais rica do que usualmente aparece nos relatos dos macroeconomistas. Esta é uma
história da construção de fatos que se mostram convincentes ao invés de serem artefatos criados pelos
modelos. Meu objetivo neste artigo é analisar a convergência entre a macroeconomia RBC e a novo-
keynesiana sob a ótica da construção de fatos através da manipulação de modelos.

Palavras-Chave: macroeconomia              DSGE,      nova     síntese    neoclássica,    real   business     cycle,
macroeconomia novo-keynesiana


                                             ABSTRACT:
In the origins of the dynamic stochastic general-equilibrium (DSGE) macroeconomics there is a
merging of two strands of the literature that were previously seen as antagonistic: the real business
cycle (RBC) and the new Keynesian macroeconomics. In the process through which each group
decided to incorporate important elements from the other camp, the persistence of “facts” is usually
referred to – Blanchard (2009) is emblematic here for having written that “facts have a way of not
going away.” However, empirical facts play a role in macroeconomics hardly similar to the ideal
falsificationism, as the very facts are constructed with the help of models they are aimed to assess.
Thus, a central issue is to understand the degree of autonomy of facts from models and, therefore, the
ability of facts in convincing the economists from the opposing camps. As a consequence, the story of
facts forcing RBC and new Keynesian macroeconomists to incorporate in their models elements from
the antagonistic group is richer than usually told. It is a story of building facts and of convincing that
they are not artifacts. My goal in this paper is to scrutinize this episode of building facts that led to a
new consensus in macroeconomics with models that bridged the two opposing camps.

Keywords: DSGE macroeconomics, new neoclassical synthesis, real business cycle, new Keynesian
macreoconomics


                Área ANPEC: 01                                    Classificação JEL: B22, B23




1
  Department of Economics, University of São Paulo, Brazil (pgduarte@usp.br). Financial support from CNPq (Brazil) is
gratefully acknowledged.
From real business cycle and new Keynesian to DSGE Macroeconomics: facts and
models in the emergence of a consensus
Introduction
        By the late 1990s and early 2000s, several mainstream macroeconomists were trumpeting that
they have reached a consensus in the literature of business fluctuations. So, they argued, past was the
time when their field was deeply divided, with alternatives schools of thought criticizing one another
“as wrong from the ground up”, as Robert Solow (1983, 279) put it (cf. Duarte 2012). By then,
dynamic stochastic general-equilibrium (DSGE) models have become the staple.
        How could a shared core view on fluctuations and on the appropriate methodology for
macroeconomics emerge? Olivier Blanchard (2009) stressed that facts, which “have a way of not going
away” (210), “[force] irrelevant theory out” (212) – although he recognized that good theory can also
force “bad theory out” (212). Michael Woodford (2009, 268) explained that “positions that were
vigorously defended in the past have had to be conceded in the face of further argument and
experience.”
        The role of facts in theoretical disputes is often stressed in different episodes of the history of
macroeconomics. In particular, as the previous quotes indicate, it is central to the protagonists’
narratives on how antagonists theories – new classical (and real business cycle, RBC), on the one hand,
and new Keynesian, on the other – were eventually synthesized into the DSGE macroeconomics. In
such narratives, mainstream macroeconomists tend to hold loose methodological and philosophical
ideas about facts falsifying theories, about paradigms being challenged, and school of thoughts winning
bitter battles, all of this in favor of some type of knowledge accumulation (Duarte 2012, 190-4).
        However, those narratives tend to underplay the complexity of the very nature of “facts” in
macroeconomics. How can macroeconomists observe the workings of an economy? Essentially through
building and manipulating models. Thus the construction of macroeconomic facts, of empirical
regularities that come to be accepted by many economists (or by dominant groups), brings a richer
array of elements to the simpler story of groups retreating and reaching a consensus because facts
stubbornly do not go away.
        As Mary Morgan (2011, 7) characterized them, facts are “settled pieces of knowledge that we
can take for granted.” Therefore, reaching a consensus requires a negotiation about which are the
relevant facts, and they better be separable “from their production context and shared with others”
(Howlett and Morgan 2011, xv). Facts are thus not artifacts produced by our observational apparatus,
but are empirical regularities widely accepted by scientists. Facts hold intricate relationships with
models that economists construct (cf. Boumans 2005 and Morgan 2012), and they have to travel across
competing macroeconomic models in order to be accepted as general and true.
        My goal in this paper is to examine the arguments put forward by mainstream economists for
the emergence of the new consensus that Marvin Goodfriend and Robert King (1997) labelled the “new
neoclassical synthesis.”2 In doing so I want to give narrower meaning and apply the ideas about facts
just mentioned to the macroeconomics of fluctuations literature. I also want to take into account
Morgan’s (2012) insights on the centrality of modeling as the dominant methodology in economics
after the 1930s.3 Without aiming to be exhaustive, I shall brush through important empirical debates
between RBC and new Keynesian economists and highlight theoretical commitments involved in them.
        In order to examine the construction of facts and their role on the emergence of the DSGE
consensus, in Section 1 I first discuss the common understanding of what a cyclical fluctuation is that
new Keynesians and RBC macroeconomists share. I also stress the idea that became increasingly
important in mainstream macroeconomics: that business cycle models ought to account for some
“stylized facts” – which have a degree of autonomy from the instruments used to identify them. Finally,
I point out the centrality that shocks have in modern macroeconomics, with its Lucasian philosophy

2
  See De Vroey and Duarte (2013) for a historical comparison of the neoclassical synthesis of the 1950s and 1960s with the
new neoclassical synthesis.
3
  See also Boland (2014) for a discussion of model building in recent economics.

                                                                                                                        1
about what models are. Once we clarified these three issues, we proceed, in Section 2, to the core
contribution of this paper: to analyze the emergence of the DSGE macroeconomics by the negotiation
involved in building “stylized facts.”4 This negotiation between new Keynesian and real business cycle
macroeconomists involved the decomposition of variables into trend and cyclical components, the
debate over which are the important shocks and how much persistence there are in propagation
mechanisms, and a set of additional evidence that favored the new Keynesian view, at the core of
DSGE macroeconomics, that nominal shocks have real effects in the short run.


1. Cycles, Stylized Facts, and Shocks

        The idea that there are empirical regularities related to business fluctuations that can serve to
discriminate and select theories is implicit in the concept of cycles that new classical, real business
cycle, and new Keynesian macroeconomists share. Going back to the study of cycles by Arthur Burns
and Wesley Mitchell (1946), these economists recognize that despite the differences in amplitude and
scope, individual cycles have common elements.
        Burns and Mitchell (1946, 3) were clear that they were proposing a “tool of research” when they
put forward their working definition of business cycles:

         Business cycles … [consist] of expansions occurring at about the same time in many
     economic activities, followed by similarly general recessions, contractions, and revivals
     which merge into the expansion phase of the next cycle; this sequence of changes is
     recurrent but not periodic; in duration business cycles vary from more than one year to ten
     or twelve years; they are not divisible into shorter cycles of similar character with
     amplitudes approximating their own.

        So business cycles are different from other types of fluctuations. They occur in many activities,
have a recurrent sequence of phases (expansion, contractions, and revivals), and have varied but
somewhat long duration. The “typical” characteristics of cyclical behavior would be, for example, the
timing, duration (mean lengths of expansions and contractions), amplitude, change in the average level
of indicators, and conformity of individual series (each representing a particular economic process) to
the overall cycle.5
        While modern macroeconometricians have mostly abandoned the methodology of Burns and
Mitchell (1946),6 a similar characterization of cycles can be found thirty or so years after their work.
For instance, Victor Zarnowitz (1985) wrote in his lengthy and mostly theoretical survey on the
business cycle literature:

          The term “business cycle” is a misnomer insofar as no unique periodicities are
     involved, but its wide acceptance reflects the recognition of important regularities of long
     standing. The observed fluctuations vary greatly in amplitude and scope as well as
     duration, yet they also have much in common. First, they are national, indeed often
     international in scope, showing up in a multitude of processes… Second, they are
     persistent – lasting … long enough to permit the development of cumulative movements
     in the downward as well as upward direction.

        He then reports in some detail the “stylized facts” of business cycles in the US, and some
international evidence as well (pp. 525-33).

4
  I am not claiming that the negotiation involved only empirical matters, and I explored elsewhere the theoretical and
methodological compromises related to the emergence of DSGE macroeconomics (Duarte 2012).
5
  Burns and Mitchell (1946) recurrently use the adjective “typical” in their analysis.
6
  Blanchard and Fischer (1989, 7) claimed that “[t]his is because [Burns and Mitchell’s] approach is partly judgmental and
the statistics it generates do not have well-defined statistical properties.”

                                                                                                                        2
        Robert Lucas was very important in passing it along a modern definition of cycles that
mainstream macroeconomists of different stripes adopt. When he discussed the Phillips curve, Lucas
(1973, 327) characterized cycles as fluctuations of output about trend: the quantity supplied in each
market has “a normal (or secular) component common to all markets and a cyclical component which
varies from market to market.”7 Two years later, while proposing a competitive equilibrium model of
the business cycle, Lucas (1975, 1113) implicitly characterized cycles as “serially correlated, ‘cyclical’
movements in real output” which are accompanied by “procyclical movements in prices, in the ratio of
investment to output, and, in a rather special sense, in nominal interest rates.” But we find a more
elaborate discussion in Lucas (1977), where, referring to Burns and Mitchell (1946), he reviewed “the
main qualitative features of economic time series which we call ‘the business cycle,’” defined as the
joint dynamic behavior of deviations of variables from trend. He wrote:

          Those regularities which are observed are in the co-movements among different
     aggregative time series… There is… no need to qualify these [co-movements] by
     restricting them to particular countries or time periods: they appear to be regularities
     common to all decentralized market economies. Though there is absolutely no theoretical
     reason to anticipate it, one is led by the facts to conclude that, with respect to the
     qualitative behavior of co-movements among series, business cycles are all alike.
     Lucas (1977, 9-10)

         Lucas’s characterization of cycles as being alike, when one looks to the movements of
deviations of variables from trend, became the traditional characterization for either Bruce Greenwald
and Joseph Stiglitz (1988, 211), or Finn Kydland and Edward Prescott (1982, 1990), leading Blanchard
and Fischer (1989, ch. 1) to present it as standard in their graduate textbook.
         As a result, a clear empirical dimension was taken as central for testing business cycles models
and theories: comovements of aggregate variables. Together with other statistics as variance of
variables, autocorrelations, and average levels, comovements became the “stylized facts” that fueled
the fights between real business cycle and new Keynesian theorists in the 1980s and early 1990s –
“[a]fter all, it is the ‘stylized facts’ which it provides that ought to be explained by the theory,” as
Zarnowitz (1985, 524) put it.
         Here there is a curious transformation of the use of the expression “stylized facts”. This term is
often associated with Nicholas Kaldor (1957) (cf. King and Rebelo 1999, 941): while not present in this
article, Kaldor used it in print in 1961 (Kaldor 1961).8 Aiming to have a theoretical model that captured
the nature of the growth process, Kaldor (1957, 591-3) reported the “remarkable historical constancies”
revealed in investigations at the time (by several authors, including Simon Kuznets), which “[a]
satisfactory model concerning the nature of the growth process in a capitalist economy must also
account for” (Kaldor 1957, 591).
         The idea is that some economic relations revealed themselves to be relatively stable, though not
numerically constant. One of these facts was the “remarkable constancy” (or “relative stability”) of the
share of wages in the national income for over a century in developed capitalist economies like the US
and the UK (Kaldor 1955, 84; 1957, 591-2). True, this constancy was not taken for granted
instantaneously by the whole economics profession as the criticisms by Solow (1958) and Irving Kravis
(1959) illustrate: they raised issues of both how to have a rigorous understanding of “relative stability”
and data discussions (which data to use, what to include as income, etc.).



7
  Clearly, Lucas was not introducing a new understanding of cycles here. Concerns about decomposing economic time
series into cyclical and other components was integral to the early literature on business fluctuations, as discussed by
Morgan (1990, chs. 1-3) and Klein (1997, chs. 9-10). But as Lucas was important in shaping the research agenda of both
real business cycle and new Keynesian macroeconomists, his views on cycles are relevant.
8
  This 1961 article is “an extended written version of an address delivered … orally” to a 1958 International Economic
Association conference on the theory of capital (Kaldor 1961, 177). Thus, from the text it is not clear whether the term was
present in Kaldor’s original address. See Boland (2008) for a discussion of “stylized facts” centered around Kaldor.

                                                                                                                          3
       When Kaldor (1961, 178) introduced the language of stylized facts to justify his methodological
position that they ought to guide the abstractions needed in theoretical enterprises, he wrote:

           … the theorist … ought to start off with a summary of the facts which he regards as
     relevant to his problem. Since facts, as recorded by statisticians, are always subject to
     numerous snags and qualifications, and for that reason are incapable of being accurately
     summarized, the theorist … should be free to start off with a “stylized” view of the facts –
     i.e. concentrate on broad tendencies, ignoring individual detail, and proceed on the “as if”
     method, i.e. construct a hypothesis that could account for these “stylized” facts, without
     necessarily committing himself on the historical accuracy, or sufficiency, of the facts or
     tendencies thus summarized.

        Economists soon took up this language: the term “stylized facts” in the economics journals
available in JSTOR appeared in two articles published in June of 1962: Paul Samuelson (1962, 194)
talked about Kaldor’s “‘stylized’ – i.e., non-rigorous but suggestive – description of a modern
economy”, and Vernon Smith (1962, 488) referred to Kaldor as someone who wanted growth models to
“be consistent with certain approximate (or ‘stylized’) facts.”
        Alluding to non-rigorous and approximate empirical evidence, business cycle macroeconomists
extended this idea of “stylized facts” beyond a description of long-term behavior to characterizing
comovements of aggregate variables over the cycle (cf. Blanchard and Fischer 1989, 15-20). It is
impressive how this language of stylized facts has become pervasive among macroeconomists since
then. A search in economics journals in the JSTOR archive, displayed in Table 1, show that it had very
little use in macroeconomics in the decades immediately after Kaldor’s 1957 and 1961 articles.
However, the use of “stylized facts” grew quickly from the 1980s onwards, reaching a substantive level
in the 2000s.

                                         Period            Percentage of articles
                                          1960s                         0
                                          1970s                       1.0
                                          1980s                       4.0
                                          1990s                       6.9
                                          2000s                       10.0

                                    Table 1: Frequency of “stylized facts” in
                                      macroeconomics articles in JSTOR9

        Correlations and comovements could be seen as basic statistics, along with means and
variances. But it is hard to characterize them as non-rigorous and approximate pieces of evidence since
they are computed with precise formulas from accurate data (in contrast to the type of data that
concerned Kaldor). They are non-historically specific behavior of aggregate variables, which, thus, is
conceptually “stylized” in the sense of being related to broad economic tendencies in many economies.
        Moreover, the matter that modern economists understand stylized facts to be non-rigorous and
approximate indicates the complex process of observing macroeconomic phenomena, and the intricate
relationship data has with models. The modern use of stylized facts also express an “ambiguity between

9
  This table shows the percentage of economics articles (available in the JSTOR archive) that contained “stylized facts”
among those which had the word “macroeconomics.” As both Samuelson (1962) and Smith (1962) did not have in their
texts “macroeconomics,” they are not recorded in the second line of the table. Just to give an idea of magnitude, in the 1970s
(i.e. 1970-1979) only nine articles contained “stylized facts” (and “macroeconomics”). This number soared to five hundred
and forty in the 2000s.

                                                                                                                            4
data and phenomena, an ambiguity between the observable and the inferred” (Duarte and Hoover 2012,
227).10 In a rather unique understanding, but one which also point to the ambiguity between data and
phenomena, John Campbell and N. Gregory Mankiw (1987b, 111) opened their article defining stylized
fact as “an empirical claim that is widely believed but the evidence for which is only mixed.” Therefore
stylized facts are subject to constant and substantial reexamination over time, and they may eventually
go away instead of staying and forcing theories to adjust to account for them.
        What is more stylized, in the sense of being an approximation, in the comovements
macroeconomists report is, for example, the way they construct and compare the cyclical components
of the variables of interest. In order for the comovements and other indicators to be understood as
stylized facts, economists have to agree that the data was manipulated satisfactorily, and that that piece
of knowledge is autonomous in relation, or robust, to the way it was produced: facts that travel across
models and theories, not artifacts. The issue becomes further complex when stylised facts become more
elaborate evidence coming out of econometric exercises such as impulse response functions from a
vector-autoregression (VAR) model, as it is common in the DSGE literature. Therefore, as we shall see,
part of the battles among RBC and new Keynesian macroeconomists dealt with facts that count, with
robustness, with data manipulation, etc.
        Finally, there is one sense in which any statistical methods for collecting data can only provide
stylized facts. The well-known “Lucas critique” (Lucas 1976) brought the need of estimating structural
models in applied macroeconomics if one is to use models for comparing alternative policies. So, this
argument goes, estimating reduced-form models can only provide approximate relationships between
variables (valid for a given policy regime), which could be interpreted as “stylized facts” that any
theoretical model should match. But once again, these empirical findings are hardly facts that stay put:
variance decomposition and impulse response analysis coming out of an estimated VAR depend on
things like the ordering of the variables in the VAR (identification issues more broadly), and thus there
is room for discussing how robust a given fact is.
        Besides the issues of defining and characterizing cycles, and of the stylized facts that matter, the
debates RBC and new Keynesian economists held in the 1980s and 1990s (and the consensus view of
DSGE macroeconomics) reflect another key development: the particular way of observing the
economy, with models in which exogenous shocks are central. Therefore the resolution of
disagreements passed also through discussions about how to identify shocks, which ones (if nominal or
real shocks) explain most of the observed data of a given economy in a given time span, and what is the
dynamic propagation of shocks in the economy. While this modeling strategy of shocks and
propagation mechanisms had Ragnar Frisch (1933) as an important early contributor, that a particular
understanding of shocks rose to prominence in modern macroeconomics due to the rational
expectations hypothesis promoted by Lucas and other new classical economists and the VAR
econometric approach of Christopher Sims (Duarte and Hoover 2012). The ubiquitous role of shocks in
modern business cycle studies is well represented in the following passage of Michael Wickens’s
(2008, 27) graduate textbook:

          In practice an economy is continually disturbed from its long-run equilibrium by
     shocks. These shocks may be temporary or permanent, anticipated or unanticipated.
     Depending on the type of shock, the equilibrium position of the economy may stay
     unchanged or it may alter; and optimal adjustment back to equilibrium may be
     instantaneous or slow. The path followed by the economy during its adjustment back to
     equilibrium is commonly called the business cycle, even though the path may not be a
     true cycle.


10
  Stefan Mendritzki (2014) stressed the varied uses of “stylized facts” in many areas of economics without a clear definition
of what they are. He proposed to see them as mediators between models and empirical evidence, aiming to assess their role
in empirical evaluation of models. I find that this characterization does not illuminate much the practice of observing the
economy as a whole and building facts. Therefore, I emphasise here the mediating role of models (following Boumans 2005
and Morgan 2012).

                                                                                                                           5
        In conclusion, the empirical battle that new classical, RBC, and new Keynesian
macroeconomists were engaged involved a multitude of elements related to building a set of stylized
facts for economic fluctuations that are all alike in the comovements of series: of decomposing
variables into trend and cyclical components, of manipulating data more generally, of identifying the
shocks that explain most of the cyclical fluctuations observed in developed economies, of having
theoretical models in which these external shocks can replicate the observed macroeconomic dynamics,
among others. So, in contrast to Blanchard’s (2009) emphasis, the building of the new consensus had
more than just a set of stubborn facts that did not go away and, thus, forced economists to reevaluate
positions and concede somewhat to the opponent’s view. The facts themselves were negotiated.


2. Building Facts and Battling Over Them

        My goal in this section is to analyze important empirical points of contention between new
classical and RBC macroeconomists, on the one hand, and new Keynesians, on the other. In doing so, I
shall explore how original dissent was turned into the consent of the DSGE macroeconomics. However,
there is no hope of either being exhaustive or listing them in order of relevance to the emergence of the
DSGE models. I see a multitude of elements – some intertwined, others not – who gave varied
contributions to the rise of the new consensus.
        Before taking stock of the contended issues, it is important to have clear in mind that the new
Keynesian literature evolved as a collection of different enterprises, each trying to provide “rigorous
microeconomic foundations for the central elements of Keynesian economics” (Mankiw and Romer
1991b, 1). Gregory Mankiw and David Romer (1991b) in their “whirlwind tour of new Keyensian
economics” indicate seven such enterprises: (1) costly price adjustment (which makes nominal shocks
generate aggregate fluctuations); (2) the staggering of wages and prices (nominal frictions that make
not all prices and wages change simultaneously); (3) imperfect competition in goods markets; (4)
coordination failures; (5) the labor market (with two major themes: unemployment and the cyclical
behavior of real wages and unemployment); (6) credit market imperfections; and (7) cyclical behavior
of firms’ markups (good markets). With hindsight, the strands that were more present at the DSGE
consensus of the early 2000s (i.e. prior to the crisis initiated in 2007-2008) are (1) and (3), with smaller
contributions of (2) and parts of (7): the basic canonical DSGE model had no room for unemployment,
financial frictions, and coordination failures. Therefore, my list of contended issues will focus more on
those strands that are present in the DSGE macroeconomics and it will be silent about the others.
        Besides recognizing the different strands that constitute the new Keynesian macroeconomics,
another element that will be important in my narrative is the differences that exist between new
classical and RBC macroeconomics. While RBC macroeconomics is an offspring of the new classical
research program, and both represent a “classical” stance (in contrast to the “Keynesian” one) that
government intervention is generally not desirable because fluctuations are optimal responses of private
agents to shocks, there are three major differences between these approaches (Duarte 2012, 198-202).
The first refers to the empirical methods employed. Originally, new classical macroeconomists
developed both solution and estimation methods to bring their models to the data. In contrast, the RBC
enterprise had a clear stance against estimation, advocating instead that model parameters ought to be
calibrated. The second difference is the fact that Lucas was particularly in favor of monetary models of
the cycle, while RBC models were mostly non-monetary models in which fluctuations were driven by
technology shocks. And the third difference is related to the way they treated information: Lucas
adopted imperfect information and the RBC theorists generally opted for a world of perfect information
(and perfect competition).
        It is intriguing that the RBC stance against estimation rests also on the very particular
understanding of models proposed by Lucas (1980, 697): that “[a] ‘theory’ is … an explicit set of
instructions for building a parallel or analogue system – a mechanical, imitation economy. A ‘good’
model, from this point of view, will not be exactly more ‘real’ than a poor one, but will provide better



                                                                                                          6
imitations.”11 For Kydland and Prescott models are workable approximations and not ‘realistic’
representations of the world. Therefore it simply makes no sense to choose parameters of a model that
generates the best fit of this model to the business cycle data, as there are many dimensions in which
the model is wrong and for which it will be penalized in estimation procedures. For them, there was no
surprise in Eichenbaum and Singleton’s (1986, 100) conclusion that econometric evidence was
unfavorable to RBC models when these were “subjected to formal methods of estimation and inference
which incorporate a fairly comprehensive set of moment restrictions.”
        If models are analogue systems, mechanical imitations of the economy, they better be discussed
in terms of reproducing stylized behavior or broad tendencies of macroeconomic series, leaving aside
specificities and particularities. Combining this understanding about models with calibration and a
stylized approach to evaluating models (many times without a clear metric for judging how close model
and data moments are), we have much room for macroeconomists to battle over “facts.” Let us now
discuss some important issues over which much negotiation among the different groups (the classical
and the Keynesian ones) took place.
2.1 Trend and Cycle
        Clearly, a key issue for empirical studies of the business cycle is to decompose output
fluctuations into trend and cyclical components. Focusing roughly on the period from the 1980s
onward, the period of battles between RBC and new Keynesian economists, one standard way was to
define that a given series (output, for instance) fluctuates along a deterministic smooth trend (with
many possible specifications: quadratic, exponential, linear, or any other functional form). This
econometric characterization of a trend-stationary series can be justified entirely on statistical grounds,
and it assumes that what determines the long-run growth of the series is not what generates cyclical
fluctuations. Moreover, in this view series tend to return to their deterministic trends as cyclical
fluctuations are temporary deviations from trend. The common practice that follows this
characterization is to fit a deterministic trend to data and get the difference between the actual value of
the variable and the trend as the cyclical component. This is what Lucas (1973) by decomposing the
quantity supplied in each market into “a normal (or secular) component common to all markets and a
cyclical component which varies from market to market” (327). He argued that the secular component
reflected long-run growth (capital accumulation and population change) and he modeled it as a linear
deterministic trend. For Lucas, the cyclical component depended stationarily on its own past value and
on agents’ perceptions about relative prices.
        The time series studies of the 1970s on unit roots brought a rather different understanding which
had a significant impact on macroeconomics: trends can be stochastic rather than smooth and
deterministic (see also Qin 2013, 103-7). With this new interpretation, permanent shocks would affect
the trend while transitory shocks (whose effects on the series vanish over time) determine cyclical
fluctuations. The possibility of non-stationary series led to an important criticism by Charles Nelson
and Charles Plosser (1982, 140): “If the secular movement in macroeconomic time series is of a
stochastic rather than deterministic nature, then models based on time trend residuals are misspecified.”
The authors argued that a set of long historic US time series (more than sixty years of annual data)
indeed exhibited stochastic trends. Their criticism to the practice of detrending series with a
deterministic trend applied both to economists of the new classical and RBC camp (Nelson and Plosser
cited Lucas, Barro, Sargent, and Kydland and Prescott) as well as to Keynesians (John Taylor).
However, as we shall explore in the next section, their study lent credibility to the RBC strategy of
proposing an equilibrium model with a stochastic trend (affected by real shocks), leaving not much
room for temporary monetary shocks to explain much of output fluctuations (Nelson and Plosser 1982,
141).
        Either of the two characterizations of trend were not appealing to Zarnowitz (1985), for
example. He sided with Nelson and Plosser (1982) in dismissing the deterministic characterization on
the ground that it does not take into account the subtle and varied ways in which “business cycles


11
  Lucas (1980) briefly mentioned Herbert Simon’s 1969 book Sciences of the Artificial as an ancestor of his understanding
of an economic model, using the idea of artifacts. See Hoover (1995, especially 35-7) for a detailed discussion of this point.

                                                                                                                            7
interact with long-term trend” (545).12 Notwithstanding, he dissented from their proposal for stochastic
trend (with the cycle thus being “largely pure noise”) appealing to economics: “There is no good
economic theory to justify this way of looking the world” (Zarnowitz 1985, 545-6).13
        On their turn, from the Keynesian side, Campbell and Mankiw (1987a) followed and extended
Nelson and Plosser’s stochastic trend analysis. They also criticized the pervasive understanding that
output returns to trend – i.e. that output fluctuations are transitory – associating this understanding to a
particular theory: the natural rate theory, which imply that fluctuations are just temporary deviations of
output from its natural level that “grows at a more or less constant rate” (857). Campbell and Mankiw
(1987a) focused exclusively on the US output series in the postwar period and cautiously concluded
that “shocks to GNP are largely permanent” (858), but did not subscribe to Nelson and Plosser’s
conclusion that this evidence favors RBC models.14 More important to the present narrative is
Campbell and Mankiw’s (1987a, 858) aim “to establish a stylized fact against which macroeconomic
theories can be measured:” output shocks are highly persistent. If the change in the trend component is
serially correlated, that persistence “is consistent with a substantial cyclical component” (877), so that
demand shocks matter even if output trend being determined by supply shocks. Therefore, Keynesian
models of nominal rigidity (such as Fischer’s staggered contract model) and the Lucasian model of
misperceptions “could be reconciled with findings of persistence” (877). The literature subsequently
moved from a discussion focused only on output to a discussion of the joint stochastic behavior of
output and unemployment (cf. Blanchard and Fischer 1989, ch. 1).
        From the RBC side of this dispute, Prescott (1986) opted for treating “trend,” a “slowly varying
path” (13), as a purely statistical device used to get the cyclical components of the macroeconomic
series. This trend is “defined by the computational procedure used to fit the smooth curve through the
data” (13). Would the results of his analysis be sensitive to the detrending method? No, Prescott (1986,
13) answered: “the key facts are not sensitive to the procedure if the trend curve is smooth.” Based on a
joint work of 1981 with Robert Hodrick at Carnegie Mellon University (only published in 1997),
Prescott (1986) then proposed a smooth trend that later came to be known as the “Hodrick-Prescott
(HP) filter.”15 There is a smoothing parameter (a Lagrange multiplier of the restriction to the
minimization problem that defines the filter) that he simply set it to 1600, on the ground that “[t]his
produces the right degree of smoothness in the fitted trend when the observation period is a quarter of a
year” (Prescott 1986, 14). Later, Hodrick and Prescott (1997) brought an economic justification for
seeing cycles as “fluctuations … that are too rapid to be accounted for by slowly changing
demographic and technological factors and changes in the stocks of capital that produce secular growth
in output per capita” (1). Furthermore, they discussed more thoroughly the choice of the smoothing
parameter and argued that it does not affect the “standard deviations and autocorrelations of cyclical
real GNP” (4).
        The HP filter became a quite popular way of detrending series in modern macroeconomics, not
only among RBC followers, but a series of alternative definitions of trend was also developed (see
Canova 1998).16 A rather pragmatic approach emerged with the notion that it is just one statistical way
to characterize the data, with the hope that the detrending procedure would not affect much the
summary statistics of business cycle fluctuations. But after Kenneth Singleton (1988), Robert King and

12
   James Stock and Mark Watson (1988) presented similar argument.
13
   Very recently Peter Phillips (2010, 82) has also pointed to the fact that trends have been extensively studied empirically
but are not really theoretically understood: “the empirical economist, forecaster, and policy maker have little guidance from
theory about the source and nature of trend behavior… A vast econometric literature has emerged but the nature of trend
remains elusive.”
14
   In a companion paper, Campbell and Mankiw (1987b) analyzed the literature that shows that output is persistent and also
used “the unemployment rate to separate the cyclical and trend components of real GNP” (115) concluding that both
components are highly persistent (dismissing the view that cyclical fluctuations are short-lived). But there are important
identification issues, which the authors discussed, that are central to the results they obtained.
15
   Young (2014, 30-5) recapitulates the main moves made by Hodrick and Prescott from the first draft of this paper (of
1978) to its published version.
16
   See James Stock and Mark Watson’s (1999, 10-14) survey for a discussion on detrending and for additional references of
the literature developed after Nelson and Plosser (1982).

                                                                                                                           8
Sergio Rebelo (1993) showed through examples that this filter “dramatically alters measures of
persistence, variability, and comovement” of macroeconomic series. They argued against the
widespread use of the HP filter “as a unique method of trend elimination” (207), as did Fabio Canova
(1998). Craig Burnside (1998, 514) took a pragmatic view that the different filters to extract trend and
cycle simply point to the fact that these concepts have no unique meaning among macroeconomists:

         First, [Canova (1998)] overstates his case, because there are many facts about the
    business cycle which should be accepted as being robust, especially when detrending and
    extracting business cycle components of a time series are recognized as being distinct
    exercises. Second, and more importantly, I will argue that when the facts differ according
    to the filter, this simply means there are many facts to be explained. Economists will be
    misled only to the extent that they believe that all filters designed to extract the “cyclical”
    and “trend” components of time series produce the same outcomes. Since … it is widely
    accepted that the concepts of “trend” and “cycle” do not have unique meaning among
    economists, there is not too much to worry about here…

        Therefore, what we see is that the issue of identifying trends and cycles, a critical first step for
identifying stylized facts, was source of much controversy and of calls for trusting the robustness of the
results found. It involved questioning positions from many sides: the deterministic trend that
macroeconomists of several orientations adopted; the lack of economic arguments behind a purely
stochastic trend; the univariate discussion of output dynamics; what exactly are the relevant stylized
facts (comovements and other second moments, or persistence of output?) and how robust they are;
how to characterize and identify trends and cycles. None of this prevented DSGE macroeconomists to
develop with a very pragmatic approach to the trade/cycle decomposition in which the HP filter became
a popular method employed.
        While controversies like this one about decomposing trend from cycle are not unexpected in
scientific realms, this discussion makes historically unappealing the idea that macroeconomists have
settled wide theoretical disagreements because facts forced them to adapt and concede, with DSGE
macroeconomics smoothly emerging out of this negotiation process. And this trend/cycle identification
is just one (very important) issue among others that new classical, RBC, and new Keynesian
macroeconomists discussed.

2.2.    Shocks and Propagation Mechanisms
        Another major point of controversy was the source of fluctuations and their characteristics. New
classical, RBC and new Keynesian macroeconomists held very different views both on shocks and on
propagation mechanisms. Lucas’s (1972, 1973) equilibrium model of the business cycle was based on
(real and) monetary shocks that generated price surprises (effective prices different from what agents
expected). However, this model, with market clearing and incomplete information, had not much of a
propagation mechanism through which random (temporary) monetary shocks generated persistent
fluctuations of real aggregate variables. In order to add more persistency in the propagation mechanism
Lucas (1975) introduced two novelties: information lags (which prevents past variables from becoming
perfectly known), and capital accumulation with an investment accelerator. The latter increases
persistence in a particular way: an unexpected expansionary monetary shock increases current
employment and output, but it also raises the demand of capital and its accumulation. This, in turn,
raises the productivity and the demand for labor, and subsequently increases the supply of goods.
Therefore the investment accelerator retards the price increase that ultimately happens in the economy
and generates “serially correlated ‘cyclical’ movements in real output” (Lucas 1975, 1113).
        The same concern of getting enough propagation was present in Kydland and Prescott’s (1980,
1982) model in which capital goods require time to be built, and also in the inventory investment model
of Alan Blinder and Fischer (1981) – or yet in different models using adjustment costs to hiring factors
of production. Kydland and Prescott were trying to add more persistence in the propagation
mechanisms of the standard RBC model so that they were not forced to rely in very persistent


                                                                                                          9
technological shocks. New Keynesians wanted to add rigid prices and wages to the list of propagation
mechanisms. The very same concern on shocks and propagation mechanisms led DSGE
macroeconomists to insert several other features that extended their basic three-equation model towards
the larger models that went to empirical applications (see Duarte 2011 for a discussion and references).
        Intertwined with their proposed propagation mechanism there was a divide between RBC
economists, on one side, and new Keynesians, on the other, on the shocks that mattered most to explain
observed fluctuations: the former group insisted on supply-side shocks, in particular technology shocks,
while the latter insisted on demand-side shocks, in particular monetary shocks.17 However, issues about
how to measure technological shocks and how much they explain business cycle fluctuations became a
hotly debated topic (see Eichenbaum and Singleton 1986, Summers 1986, Mankiw 1989, and
Eichenbaum 1991, for example).18
        On this issue of the relative importance of shocks Lucas (1987) was really convinced that
monetary shocks mattered empirically, and he did not side with RBC economists. For him the
fluctuations observed in the past after monetary shocks cannot be explained “by a combination of
purely real shocks and the kind of ‘propagation mechanism’ Kydland-Prescott constructed:” “we need
either much larger shocks than any that can be interpreted as ‘technology’ shocks in Kydland-Prescott
framework, or a propagation mechanism with much larger ‘multipliers’. The problem … lies in
accounting for large real fluctuations without candidates for ‘shocks’ that are of the right order of
magnitude” (71).19 In a set of letters from 1990 between Lucas and Prescott (cited in Duarte 2012, 201),
it is very clear that Lucas insisted on the importance of monetary shocks – “I think the hard part of a
monetary theory is getting a coherent picture of the impulses” – while Prescott argued that “a problem
for monetary shock theories of business cycle fluctuations is the lack of a propagation mechanism.”
        RBC macroeconomists used two major “facts” to support their view that real (supply-side)
shocks matters mostly and that monetary (demand-side) shocks are unimportant. As Kydland and
Prescott (1990) reported (against some of the regularities listed by Lucas 1977, 9), the first fact is that
in the data prices are countercyclical instead of procyclical. This implies that for prices and output to
move in opposite direction, they ought to result from shifts in the aggregate supply function along a
given aggregate demand. However, for Ball and Mankiw (1994, 133-4) the countercyclicality of prices
was not a fact, but rather an artifact produced by detrending macroeconomic series with the HP filter.
The second fact Kydland and Prescott (1990) used was that monetary aggregates do not lead the cycle,
contrary to the evidence associated with the works of Milton Friedman and Anna Schwartz (1963) and
Sims (1972, 1989).
        Thus, the ages-old issue of money neutrality was fiercely disputed on empirical grounds
combined with theoretical commitments needed in such exercises. Comovements among variables,
causality (as proposed by Clive Granger 1969 and popularized by Sims 1972) between money and
output, and investigations of whether money leads output fluctuations, were just three important
dimensions of this dispute on money neutrality (Blanchard 1990, 787-91; Stock and Watson 1999, 14-
45). Importantly, part of this discussion was carried over in calibrated models in which no statistical
criteria for goodness of fit was employed, a weakness later addressed by Watson (1993) and Diebold,
Ohanian and Berkowitz (1998), for instance.
        In fact, the need of having more powerful ways of testing alternative models led several authors
to move the discussion from comovements toward comparisons of the time series sample paths
predicted by the models to the historical paths observed in the data. In the RBC literature King, Plosser


17
   It is true that Kydland and Prescott (1980) included random shocks to nominal wages, but concluded that they were
secondary. Then in their 1982 paper, they presented a model without monetary disturbances. It is also true that there were
early attempts to include money and a banking sector into an RBC model, such as that of King and Plosser (1984).
Nonetheless, the RBC literature of the 1980s is mostly associated to real (non-monetary) models.
18
   See also Danthine and Donaldson (1993) and Hartley, Hoover and Salyer (1997). Young (2014, 140-7) recounts in detail
this empirical debate.
19
   Lucas (1987, 72) noted that this is not a question that Kydland and Prescott dealt with, as they chose the variance of their
technological model so that it replicated the observed GNP variance. So they did not calculate the Solow residual
independently from their model to then check how much it explains of output variability.

                                                                                                                            10
and Rebelo (1988) and Christiano (1988) made early contributions to this end.20 As Smith and Zin
(1997, 244) recognized, focusing on moments such as comovements and variances provides a general
analysis “if shock processes are similar across countries.” Therefore, testing whether models account
for historical macroeconomic behavior implies bringing historical specificities to the picture and, thus,
going somewhat against the view that cycles are all alike and can be well described by a set of stylized
facts. Nonetheless, this type of analysis for model selection did not become dominant in the RBC and
new Keynesian literatures that led to the DSGE macroeconomics.
        At the time of the disagreements between RBC and new Keynesian macroeconomists,
Blanchard (1989) presented what he called “the traditional interpretation of macroeconomic
fluctuations” (his “Keynesian model”), which is the one that assigns more importance to demand-
shocks for short run fluctuations (when prices and output move in the same direction) and to supply-
shocks for the medium and the long run (when prices are countercyclical). Drawing on the
characteristics of the joint process of several macroeconomic variables (output, unemployment, prices,
wages, and monetary aggregates), Blanchard presented empirical evidence in favor of this traditional
view. Additionally, he also analyzed the dynamic effects of (structural) shocks on endogenous
variables: through both variance decomposition exercises (seeing which shocks explain most of the
variance of a given variable quarters ahead), and impulse response functions (the dynamic response of
variables to innovations in each shock). With the first exercise, he argued that output fluctuation is
dominated, in the short-run, by aggregate-demand shocks, and by supply-shocks in the long run. With
the second exercise, he claimed that the impulse functions to demand shocks “are very much consistent
with the traditional interpretation” (1158). Recognizing that both exercises are sensitive to the
identifications restrictions imposed, Blanchard (1989, 1153) argued that “impulse responses turn out to
be very similar for a large set of identification restrictions.”
        Mainstream macroeconomists’ disagreements about the effect of monetary policy on business
fluctuation remained wide, making Sims (1989, 1992) to call macroeconomists to take time-series
evidence seriously. He noticed that “[t]hough many macroeconomists would profess little uncertainty
about it, the profession as a whole has no clear answer to the question of the size and nature of the
effects of monetary policy on aggregate activity” (Sims 1992, 975). Then, going in the same direction
as Blanchard (1989), Sims (1992, 976) argued that “new reduced-form evidence on the dynamic
interactions of real and monetary variables” was key to eventually sorting out the winning side of the
debate, if “Keynesian” or RBC macroeconomists. Sims (1992) presented cross-country evidence and
then concluded that because dynamic responses of macroeconomic variables to shocks “are robust both
across countries and across definitions and lists of included variables” (976) they can be treated as facts
that can be used to select the most appropriate model to the problem at hand:

           RBC models … have … not confronted the documented impulse-response facts about
     interactions of monetary and real variables. Given the profession’s long experience with
     the Keynesian-monetarist debate, in which the limitations of evidence on correlations,
     timing, and (combining these) cross-correlation functions came to be widely appreciated,
     it is surprising that these tools are again receiving so much attention. It is not surprising
     that policy-oriented economists, well-taught by the earlier debates how easy it is to match
     a given pattern of correlations or timing with models that have widely different
     interpretations, do not regard this kind of exercise with RBC models as convincing.
     Sims (1992, 980)

       At that time, other macroeconomists advocated the use of other type of time-series evidence: the
spectrum of macroeconomic series (which indicates how much different frequencies – if business cycle
or long-run frequencies – contribute to explain the variance of a given series), such as Watson (1993)
and King and Watson (1994). The latter argued that growth rates of several macroeconomic series had

20
  Charles Plosser’s (1989) overview of the RBC literature is often cited as one of the first to compare predicted and actual
paths. See Hoover and Salyer (1998) for a thorough analysis of the ability of RBC models to match historical
macroeconomic behavior.

                                                                                                                         11
a spectrum of a given shape and this, together with the usual comovements among variables,
constituted the “two sets of stylized facts about postwar U.S. business cycles” that a good model ought
to capture well (King and Watson 1994, 43). Borrowing the title of an older article by Granger (1966),
throughout the paper they called the first of them “typical spectral shape for growth rates,” which King
(1995, 87) was not hesitant to refer as “a major stylized fact of business cycles.”
         Sims’s (1992) conclusion that the evidence that money matters but not as significantly as other
authors believed it did was furthered in Martin Eichenbaum’s (1992) comments to this work. For him,
the matter of the real effects of monetary shocks is less clear because different identified monetary
shocks generate very different dynamic relationships among macroeconomic variables and that Sims’s
paper “serves as a timely reminder of the possible dangers involved in using small subsets of simple
correlations or ‘stylized facts’ as tests of competing business cycle theories.” But his view was “that the
actual extent of our uncertainty is substantially understated by Sims analysis. … [T]here exist …
plausible measures [of monetary shocks] which generate very different inferences regarding the effects
of monetary policy” (Eichenbaum 1992, 1001-2). For him, only a careful study of the “institutional
details of how monetary policy is actually carried out in the different countries” (1010) could clarify
which variables (interest rate, monetary aggregates, etc.) summarize the monetary policy, so that
dynamic responses to a well-identified monetary shock can be studied econometrically and then be
compared to the theoretical responses coming out of different macroeconomic models.
         In the authoritative literature review of Christiano, Eichenbaum and Evans (1999) they
recognized that because countries have different monetary policy institutions and rules, a purely
statistical investigation on money neutrality is not feasible. Instead, given that “real world
experimentation is not an option,” “[t]he only place we can perform experiments is in structural
models” (p. 67) by subjecting them to a shock for which we are “fairly certain how actual economies or
parts of economies would react” (citing Lucas 1980). For the critical issue of identifying a monetary
shock, the authors relied on the robustness of the results obtained with alternative identifying strategies:

         The … literature has not yet converged on a particular set of assumptions for
     identifying the effects of an exogenous shock to monetary policy. Nevertheless, as we
     show, there is considerable agreement about the qualitative effects of a monetary policy
     shock in the sense that inference is robust across a large subset of the identification
     schemes that have been considered in the literature.
     Christiano, Eichenbaum and Evans (1999, 70)

        This alleged agreement was what allowed Galí (2008, 7-9) to describe the impulse response
functions coming out of the structural VAR models estimated by Christiano, Eichenbaum and Evans
(1999) as the major empirical evidence of monetary policy non-neutralities – comovements cannot be
used as such evidence because variables respond to all shocks hitting the economy, making it hard to
compare this with the experiment from the models. Moreover, the shape of the impulse response
functions captures an inflation inertia (and other “facts”) that models ought to replicate (Galí 2008, 8-
9). These functions then became the data for estimating DSGE model by minimizing the distance
between empirical and theoretical impulse response functions (Duarte and Hoover 2012, 241-4). But
economists are often interested in the phenomena generated by monetary shocks, thus they treat the
robust qualitative effects presented by Christiano, Eichenbaum and Evans (1999), based on particular
and disputable identification hypotheses, as crucial stylized facts that their models ought to replicate.
Although the shock phenomenon is a distinctive element contributing to the rapprochement between
new Keynesian and RBC macroeconomists, its role and importance is intertwined to several other
“facts” that placed money non-neutrality at the core of the DSGE macroeconomics.21


21
  It is important to stress that the focus on impulse response functions is not incompatible with a certain consensus that real
shocks explain most of the variance of aggregate series (see, for instance Altig et al. 2011). Nonetheless, this consensus
does not make the systematic monetary policy irrelevant to fluctuations as it shapes the equilibrium properties of the model
and the magnitude of the effects of real shocks on macroeconomic variables (Duarte 2012, 211-12).

                                                                                                                            12
    2.3. Additional Front Lines: Price Stickiness, Exchange Rates, and Imperfect Competition
         Ball and Mankiw (1994) opened their provocative article by stating: “There are two kinds of
macroeconomists. One kind believes that price stickiness plays a central role in short-run economic
fluctuations. The other kind does not” – Keynesians would be in the first group, while new classical
and RBC macroeconomists would be in the latter.22 And, for Ball and Mankiw (1994) the belief that
prices are sticky (which in turn explains money non-neutrality) was based on microeconomic studies
showing that prices change infrequently in a wide range of economic sectors. Notwithstanding this
evidence, produced by studies since the mid-1980s, in the early 1990s there was still resistance to the
idea of price stickiness, partly based on a view that no good theories for explaining it was yet available
(cf. Ball, Romer, and Mankiw [1988] 1991).
         A few other papers in the 1990s brought additional evidence from micro data that prices are
sticky, forming an alleged consensus on price rigidity that appears clearly in Taylor’s (1999) survey –
the time when the new consensus of the new neoclassical synthesis was being announced to exist
(Goodfriend and King 1997).23 Nonetheless, the importance and degree of price stickiness remained a
disputed issue in more recent years, with Bils and Klenow (2004) questioning the empirical fit of time-
dependent models and Nakamura and Steinsson (2008) bringing new evidence in favor of significant
price stickiness (both papers using data for the United States).
         The support for new Keynesian theories came also from international data. After the collapse of
Bretton Woods, and after Lucas and the rational expectations hypothesis, there was a theoretical debate
in the international economics literature on the role of price stickiness for understanding the dynamic
behavior of exchange rate (an in Dornbusch of 1976). Michael Mussa (1986) published an important
empirical work showing that the real exchange rate behaves differently under two alternative regimes
for the nominal exchange rate (fixed and floating): it is much more volatile under the floating regime
than under the fixed one, and this is “largely accounted for by the increased variability of nominal
exchange rates, with little contribution from changes in the variability of ratios of national price levels
or in the covariances between movements in nominal exchange rates and movements in the ratio of
national price levels” (Mussa 1986, 117-8). Additionally, he argued that inflation differential between
two countries move smoothly under both nominal exchange rate regimes, and that all “the observed
empirical regularities provide strong evidence against theoretical models that embody the property of
‘nominal exchange neutrality’” such as models of perfectly flexible prices that clear individual
commodity markets (118). Although Mussa’s evidence was taking seriously, other researchers
disagreed that you need price stickiness to explain them (see, for example, Stockman 1988 and
references therein).
         Building on the VAR literature of shock decomposition (supply vs. demand shocks) Clarida and
Galí (1994) refined the ways to test the nominal exchange neutrality and argued that it does not hold in
the short-run but it can hold in the long-run. In their popular graduate textbook, a few years later
Obstfeld and Rogoff (1996, 606-9) synthesized this empirical literature: “[f]or anyone who looks even
casually at international data… the idea that nominal price rigidities are irrelevant seems difficult to
sustain” (606). After all, nominal exchange non-neutrality became a fact understood to be caused by
price stickiness. In addition, in the 1980s several advanced countries reduced their inflation rates while
experiencing wild fluctuations in their nominal exchange rate – and later in the 1990s and early 2000s
several countries experienced currency crises with large exchange depreciation and little inflation
(Burnside, Eichenbaum and Rebelo 2006, 402). Therefore, price stickiness became more acceptable
also because it became crucial to explain the implied comovements between nominal and real exchange
rates.
         Additional support to new Keynesian theories came also from evidence in favor of non-
competitive good markets, with such imperfections being important for understanding business cycles.
For instance, Mark Bils ([1987] 1991) studied the cyclical behavior of prices and marginal cost,

22
   They labelled the latter “heretics,” who are “silly” and “almost pathological” people, outraging Lucas (see Lucas 1994;
Duarte 2012, 203).
23
   Taylor (1999) reported also the evidence of non-synchronized price adjustments, which favors time-dependent models (a
la Calvo and Taylor).

                                                                                                                       13
arguing that it is very countercyclical and that it “is clearly inconsistent with a perfectly competitive
view of manufacturing” (440). In similar lines, but making stronger claims, Robert Hall ([1986] 1991)
brought evidence from the field of industrial organization showing that the majority of the US
industries are non-competitive. He then he went on studying the cyclical behavior of marginal cost and
to denying that the procyclicality of measured productivity is an evidence that real shocks drive the
cycle. He makes three important claims. First, “all of those sound economic reasons [why productivity
should be procyclical]… turn out to involve non-competitive behavior” (393). Second, productivity as
measured by the so-called “Solow residual” has a bias because this calculation assumes perfect
competition (i.e., that firms charge prices equal to their marginal costs). Third, that only economy-wide
productivity shocks can create meaningful aggregate fluctuations in an economy with many (and
heterogeneous) industries. Thus, Hall ([1986] 1991, 422) concluded “that the observed procyclical
behavior of measured productivity is in some considerable part the result of market power,” i.e of firms
charging prices greater than their marginal costs.
        Given that market power is a prerequisite for having firms that do not change their prices,
evidence favoring non-competitive markets also helped support new Keynesian models of price
stickiness. Once we view the DSGE synthesis as incorporating new Keynesian elements into a dynamic
general equilibrium model typical of the RBC literature, facts that favored those elements contributed
to the merging of RBC and new Keynesian macroeconomics.


   3. Concluding Remarks

        The synthesis between RBC and new Keynesian macroeconomics, in the late 1990s, is
something that involves much more than facts confronting theories. There were important
methodological similarities between new classical and RBC macroeconomics, on the one hand, and the
new Keynesians on the other, that allowed them to negotiate. That merging also happened as each
camp wanted to or had to extend their models in the direction of their opponents’. For instance, RBC
macroeconomists struggled to have a monetary model in which to discuss inflation and monetary
policy, while new Keynesians of the 1980s wanted to extend their models to a dynamic setting (cf.
Duarte 2012).
        Nonetheless, “facts” also played an important role in the emergence of the DSGE
macroeconomics, as stressed by Blanchard (2009) and Woodford (2009). But rather than being
stubborn things that stayed and forced macroeconomists to change models to account for them, facts
are constructed with the intense use of models in order to observe macroeconomic phenomena. As
Boumans (2005) and Morgan (2012) argued, given that models function as measuring instruments that
integrate a wide range of elements coming from disparate sources, manipulating models to observe
facts necessarily brings about a set of complex and intertwined issues.
        My goal in this paper was to emphasize how a factual reasoning through a search for “stylized
facts” opened up technical spaces where macroeconomists negotiated their theoretical commitments
and eventually allowed a consensus to emerge. This stylized reasoning was part and parcel of a shared
view among mainstream macroeconomists that cycles are basically general (i.e., not country- or time-
specific) comovements among aggregate variables originated from external sources of energy, shocks.
Given this somewhat qualitative characterization, as a main first task macroeconomists had to
decompose series into trend and cycles. Far from being a mere statistical problem, we saw how
detrending was deeply connected with economic arguments about macroeconomic behavior and how
after some time one particular detrending procedure (the HP filter) became widely used despite
important criticisms to it. For this to happen, as it was the case of several other issues we discussed,
arguments about results being robust to alternative procedures were central. Robustness and a stylized
characterization of reality gave facts a degree of autonomy from the observational apparatus which in
turn allowed them to travel across competing macroeconomic models. But these settled pieces of
knowledge that macroeconomists took for granted were continuously being reevaluated and a wide set



                                                                                                      14
of “facts” favored the introduction of new Keynesian elements into the dynamic models of the RBC
literature (which was a benchmark with perfect competition and flexible prices).
         I then emphasized major discussions involved in the construction of the “stylized facts” of the
DSGE consensus. First, the critical issue of what are the sources of fluctuations (the shocks that make
the economy move about trend) and the ability of propagation mechanisms built into theoretical models
to replicate the fluctuations observed in the data. Given that these macroeconomists shared the
Lucasian view that models are mechanical, imitation economies, this discussion on shocks and
propagation mechanisms involved negotiating over the dimensions in which models are to be
evaluated, if comovements or dynamic responses to shocks, for example, and how to have a clear
statistical criteria, if any, to judge such models. Second, a set of diverse evidence favored new
Keynesian features as price stickiness (based on imperfectly competitive firms) and money non-
neutrality. But there are many other empirical sides to the battle between new Keynesians and RBC
macroeconomists, with my focus here being the central elements beneath the new neoclassical
synthesis and the shared core view on fluctuations that several mainstream macroeconomists were
proud to announce they had reached in the early 2000s.


References:

Ball, Lawrence, and N. Gregory Mankiw. (1994) “A Sticky-Price Manifesto.” Carnegie-Rochester
     Conference Series on Public Policy 41: 127-51.
Ball, Lawrence, N. Gregory Mankiw and David Romer. ([1988] 1991) “The New Keynesian
     Economics and the Output-Inflation Trade-Off.” In Makiw and Romer (1991a), vol. 1, pp. 147-
     211.
Beveridge, Stephen, and Charles R. Nelson. (1981) “A New Approach to Decomposition of Economic
     Time Series into Permanent and Transitory Components with Particular Attention to Measurement
     of the ‘Business Cycle’.” Journal of Monetary Economics 7 (2): 151-74.
Bils, Mark. ([1987] 1991) “The Cyclical Behavior of Marginal Cost and Price.” In Mankiw and Romer
     (1991a), vol. 2, pp. 417-44.
Bils, Mark, and Peter J. Klenow. (2004) “Some Evidence on the Importance of Sticky Prices.” Journal
     of Political Economy 112 (5): 947-85.
Blanchard, Olivier J. (1989) “A Traditional Interpretation of Macroeconomic Fluctuations.” American
     Economic Review 79 (5): 1146-64.
________. (1990) “Why Does Money Affect Output? A Survey.” In: Benjamin M. Friedman and Frank
     H. Hahn (eds.), Handbook of Monetary Economics, vol. 2. Amsterdam: Elsevier, pp. 779-835.
________. (2009) “The State of Macro.” Annual Review of Economics 1: 209-28.
Blanchard, Olivier J., and Stanley Fischer. (1989) Lectures on Macroeconomics. Cambridge, MA: MIT
     Press.
Blinder, Alan S., and Stanley Fischer. (1981) “Inventories, Rational Expectations, and the Business
     Cycle.” Journal of Monetary Economics 8 (3): 277-304.
Boland, Lawrence A. (2008). “Stylized Facts.” In: Steven Durlauf and Lawrence Blume (eds.), The
     New Palgrave Dictionary of Economics, 2nd ed. (online). Palgrave Macmillan.
________. (2014). Model Building in Economics: its purposes and limitations. Cambridge, UK:
     Cambridge University Press.
Boumans, Marcel. (2005) How Economists Model the World into Numbers. London: Routledge.
Burns, Arthur F., and Wesley C. Mitchell. (1946) Measuring Business Cycles. New York: National
     Bureau of Economic Research.
Burnside, Craig, Martin Eichenbaum and Sergio Rebelo. (2006) “Government finance in the wake of
     currency crises.” Journal of Monetary Economics 53 (3): 401-40.
Christiano, Lawrence J. (1988) “Why Does Inventory Investment Fluctuate So Much?” Journal of
     Monetary Economics 21 (2–3): 247–80.



                                                                                                     15
Clarida, Richard, and Jordi Gali. (1994). “Sources of Real Exchange-Rate Fluctuations: How Important
     Are Nominal Shocks?” Carnegie-Rochester Conference Series on Public Policy 41 (1994): 1-56.
Danthine, Jean Pierre, and John B. Donaldson. (1993). “Methodological and Empirical Issues in Real
     Business Cycle Theory.” European Economic Review 37 (1): 1-35.
De Vroey, Michel, and Pedro Garcia Duarte. (2013) “In Search of Lost Time: the neoclassical
     synthesis.” B.E. Journal of Macroeconomics 13 (1): 1-31.
Diebold, Francis X., Lee E. Ohanian, and Jeremy Berkowitz. (1998) “Dynamic Equilibrium
     Economies: A Framework for Comparing Models and Data.” Review of Economic Studies 65 (3):
     433-51.
Dornbusch, Rudiger. (1976) “Expectations and Exchange Rate Dynamics.” Journal of Political
     Economy 84 (6): 1161-76.
Duarte, Pedro Garcia. (2011) “Recent Developments in Macroeconomics: the DSGE approach to
     business cycles in perspective.” In Wade Hands and John Davis (eds.), The Elgar Companion to
     Recent Economic Methodology. Cheltenham, UK: Edward Elgar, pp. 375-403.
Duarte, Pedro Garcia. (2012) “Not going away? Microfoundations in the making of a newconsensus in
     macroeconomics.” In Pedro G. Duarte and Gilberto Tadeu Lima (eds.), Microfoundations
     Reconsidered: the relationship of micro and macroeconomics in historical perspective.
     Cheltenham, UK: Edward Elgar, pp. 190-237.
Duarte, Pedro Garcia, and Kevin D. Hoover. (2012) “Observing Shocks.” History of Political Economy
     44 (annual suppl.): 226-49.
Eichenbaum, Martin. (1991). “Real Business Cycle Theory: Wisdom or Whimsy?” Journal of
     Economic Dynamics and Control 15 (4): 607-26.
Eichenbaum, Martin, and Kenneth J. Singleton. (1986) “Do Equilibrium Real Business Cycle Theories
     Explain Postwar U.S. Business Cycles?” NBER Macroeconomics Annual 1 (1986): 91-135.
Friedman, Milton, and Anna J. Schwartz. (1963). A Monetary History of the United States. Princeton:
     Princeton University Press.
Frisch, Ragnar. (1933) “Propagation Problems and Impulse Problems in Dynamic Economics.” In
     Economic Essays in Honor of Gustav Cassel. London: George Allen and Unwin, pp. 171-205.
Galí, Jordi. (2008). Monetary Policy, Inflation, and the Business Cycle. Princeton, N.J.: Princeton
     University Press.
Granger, Clive W. J. (1966) “The Typical Spectral Shape of an Economic Variable,” Econometrica 34
     (1): 150-161.
________. (1969) “Investigating Causal Relations by Econometric Models and Cross-Spectral
     Methods.” Econometrica 37 (3):424-38.
Greenwald, Bruce C., and Joseph E. Stiglitz. (1988) “Examining Alternative Macroeconomic
     Theories.” Brookings Papers on Economic Activity 1988 (1): 207-60.
Goodfriend, Marvin, and Robert G. King (1997) “The New Neoclassical Synthesis and the Role of
     Monetary Policy.” NBER Macroeconomics Annual 12: 231-83.
Hall, Robert E. ([1986] 1991) “Market Structure and Macroeconomic Fluctuations.” In Mankiw and
     Romer (1991a), vol. 1, pp. 387-424.
Hartley, James E., Kevin D. Hoover, and Kevin D. Salyer. (1997). “The Limits of Business Cycle
     Research: Assessing the Real Business Cycle Model.” Oxford Review of Economic Policy 13 (3):
     34-54.
Howlett, Peter, and Mary Morgan. (2011) “Editors’ Preface.” In Peter Howlett and Mary Morgan
     (eds.), How well do facts travel? Cambridge, UK: Cambridge University Press, pp. xv-xviii.
Hoover, Kevin D. (1995) “Facts and Artifacts: Calibration and the Empirical Assessment of Real-
     Business-Cycle Models.” Oxford Economic Papers 47 (1): 24-44.
Hoover, Kevin D., and Kevin D. Salyer. (1998) “Technology Shocks or Coloured Noise? Why real-
     business-cycle models cannot explain actual business cycles.” Review of Political Economy 10 (3):
     299-327.
Kaldor, Nicholas. (1955) “Alternative Theories of Distribution.” Review of Economic Studies 23 (2):
     83-100.

                                                                                                   16
________. (1957) “A Model of Economic Growth.” Economic Journal 67 (268): 591-624.
________. (1961) “Capital Accumulation and Economic Growth.” In F. A. Lutz and D. C. Hague
    (eds.), The Theory of Capital. London: Macmillan, pp. 177-222.
King, Robert G. (1995). “Quantitative Theory and Econometrics.” Economic Quarterly (Federal
    Reserve Bank of Richmond) 81 (3): 53-105.
King, Robert G., and Charles I. Plosser. (1984) “Money, Credit, and Prices in a Real Business Cycle.”
    American Economic Review 74 (3): 363–80.
King, Robert G., and Sergio Rebelo. (1999) “Resuscitating Real Business Cycles.” In: John B. Taylor
    and Michael Woodford (eds.), Handbook of Macroeconomics, vol. 1A. Amsterdam: Elsevier, pp.
    927-1007.
King, Robert G., Charles I. Plosser, and Sergio Rebelo. (1988) “Production, Growth, and Business
    Cycles: I. The Basic Neoclassical Model.” Journal of Monetary Economics 27 (2–3): 195–232.
Klein, Judy L. (1997). Statistical Visions in Time — a history of time series analysis, 1662-1938.
    Cambridge, UK: Cambridge University Press.
Kydland, Finn E., and Edward C. Prescott. (1980) “A Competitive Theory of Fluctuations and the
    Feasibility and Desirability of Stabilization Policy.” In Stanley Fischer (ed.), Rational Expectations
    and Economic Policy. Chicago: University of Chicago Press for NBER, pp. 169-187.
________, and ________. (1982) “Time to Build and Aggregate Fluctuations.” Econometrica 50(6):
    1345-1370.
________, and ________. (1990) “Business Cycles: Real Facts and a Monetary Myth.” Federal
    Reserve Bank of Minneapolis Quarterly Review 14 (2): 3-18.
Lucas, Robert E., Jr. (1973) “Some International Evidence on Output-Inflation Tradeoffs.” American
    Economic Review 63 (3): 326-34.
________. (1975) “An Equilibrium Model of the Business Cycle.” Journal of Political Economy 83
    (6): 1113-1144.
________. (1976) “Econometric Policy Evaluation: A Critique.” Carnegie-Rochester Conference
    Series on Public Policy 11: 19-46.
________. (1977) “Understanding Business Cycles.” Carnegie-Rochester Conference Series on Public
    Policy 5: 7-29.
________. (1980) “Methods and Problems in Business Cycle Theory.” Journal of Money, Credit, and
    Banking 12 (4, pt. 2): 696-715.
________. (1987) Models of Business Cycles. Oxford: Basil Blackwell.
________. (1994). Comments on Ball and Mankiw. Carnegie-Rochester Conference Series on Public
    Policy 41: 153-5.
Mankiw, N. Gregory. (1989). “Real Business Cycles: A New Keynesian Perspective.” Journal of
    Economic Perspectives, 3 (3): 79-90.
Mankiw, N. Gregory and David Romer (eds.). (1991a) New Keynesian Economics. 2 vols. Cambridge,
    MA: MIT Press.
________, and ________. (1991b) “Introduction.” In Makiw and Romer (1991a) (pp. 1-26).
Mendritzki, Stefan. (2014) “To Stylize or Not To Stylize, Is It a Fact Then? Clarifying the Role of
    Stylized Facts in Empirical Model Evaluation.” Journal of Economic Methodology 21 (2): 107-24.
Morgan, Mary. (1990). The History of Econometric Ideas. Cambridge, UK: Cambridge University
    Press.
________. (2011) “Travelling Facts,” in Peter Howlett and Mary Morgan (eds.), How well do facts
    travel? Cambridge, UK: Cambridge University Press, pp. 3-39.
________. (2012) The World in the Model: how economists work and think. Cambridge, UK:
    Cambridge University Press.
Mussa, Michael. (1986). “Nominal Exchange Rate Regimes and the Behavior of Real Exchange Rates:
    Evidence and Implications.” Carnegie-Rochester Conference Series on Public Policy 25 (1986):
    117-214.
Nakamura, Emi, and Jón Steinsson. (2008) “Five facts about prices: A Reevaluation of Menu Cost
    Models.” Quarterly Journal of Economics 123 (4): 1415-64.


                                                                                                       17
Nelson, Charles R., and Charles I. Plosser. (1982) “Trends and Random Walks in Macroeconomic
     Time Series: some evidence and implications.” Journal of Monetary Economics 10 (2): 139-62.
Obstfeld, Maurice, and Kenneth Rogoff. (1996) Foundations of International Macroeconomics.
     Cambridge, MA: The MIT Press.
Phillips, Peter C. B. (2010) “The Mysteries of Trend.” Macroeconomic Review 9 (2): 82-9.
Plosser, Charles I. (1989) “Understanding Real Business Cycles.” Journal of Economic Perspectives 3
     (3): 51-77.
Prescott, Edward C. (1986) “Theory Ahead of Business-Cycle Measurement.” Carnegie-Rochester
     Conference Series on Public Policy 25 (1986): 11-44.
Qin, Duo. (2013). A History of Econometrics – the reformation from the 1970s. Oxford: Oxford
     University Press.
Samuelson, Paul A. (1962) “Parable and Realism in Capital Theory: The Surrogate Production
     Function.” Review of Economic Studies 29 (3): 193-206.
Sims, Christopher. (1972). “Money, Income, and Causality.” American Economic Review, 62 (4): 540-
     52.
________. (1989). “Models and Their Uses.” American Journal of Agricultural Economics, 71 (2):
     489-94.
Singleton, Kenneth J. (1988) “Econometric issues in the analysis of equilibrium business cycle
     models.” Journal of Monetary Economics 21 (2-3): 361-86.
Smith, Gregor W., and Stanley E. Zin. (1997) “Real Business-Cycle Realizations.” Carnegie-Rochester
     Conference Series on Public Policy 47: 243-80.
Smith, Vernon. (1962) “The Theory of Capital.” American Economic Review 52 (3): 481-491.
Solow, Robert M. (1958) “A Skeptical Note on the Constancy of Relative Shares.” American Economic
     Review 48 (4): 618-31.
________. (1983) “Comment on Nordhaus’s ‘Macroconfusion: The Dilemmas of Economic Policy.’”
     In James Tobin (ed.), Macroeconomics, Prices, and Quantities – Essays in Memory of Arthur M.
     Okun. Washington, D.C.: The Brookings Institution, pp. 279-84.
Stock, James H., and Mark W. Watson. (1988) “Variable Trends in Economic Time Series.” Journal of
     Economic Perspectives 2 (3): 147-74.
________, and ________. (1999) “Business Cycle Fluctuations in US Macroeconomic Time Series.”
     In: John B. Taylor and Michael Woodford (eds.), Handbook of Macroeconomics, vol. 1A.
     Amsterdam: Elsevier, pp. 3-64.
Stockman, Alan C. (1988). “Real Exchange-Rate Variability Under Pegged and Floating Nominal
     Exchange-Rate Systems: An Equilibrium Theory” Carnegie-Rochester Conference Series on
     Public Policy 29 (1988): 259-94.
Summers, Lawrence. (1986). “Some Skeptical Observations on Real Business Cycle Theory.” Federal
     Reserve Bank of Minneapolis Quarterly Review, Fall: 23-26.
Taylor, John B. (1999) “Staggered Price and Wage Setting in Macroeconomics.” In John B. Taylor and
     Michael Woodford (eds.), Handbook of Macroeconomics. New York: Elsevier, pp. 1341-97.
Watson, Mark W. (1993) “Measures of Fit for Calibrated Models.” Journal of Political Economy 101
     (6): 1011-41.
Wickens, Michael. (2008) Macroeconomic Theory: a dynamic general equilibrium approach.
     Princeton: Princeton University Press.
Woodford, Michael. (2009) “Convergence in Macroeconomics: Elements of the New Synthesis.”
     American Economic Journal: Macroeconomics 1 (1): 267-79.
Young, Warren. (2014). Real Business Cycle Models in Economics. London: Rutledge.
Zarnowitz, Victor. (1985) “Recent Work on Business Cycles in Historical Perspective: a review of
     theories and evidence.” Journal of Economic Literature 23 (2): 523-80.




                                                                                                18
